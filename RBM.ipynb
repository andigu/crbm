{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "RBM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZogXIPJPPtpP"
      ],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andigu/crbm/blob/main/RBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s780vxyBu_pm"
      },
      "source": [
        "import tensorflow as tf \n",
        "import tensorflow_probability as tfp\n",
        "import numpy as np \n",
        "from sklearn.neural_network import BernoulliRBM\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZogXIPJPPtpP"
      },
      "source": [
        "# Real RBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMlzfYznvBfV"
      },
      "source": [
        "class RBM(tf.keras.models.Model):\n",
        "    def __init__(self, nv=2, nh=20, **kwargs):\n",
        "        super(RBM, self).__init__(**kwargs)\n",
        "        self.nv, self.nh = nv, nh\n",
        "        self.W = tf.Variable(tf.random.normal((nv, nh)), trainable=True)\n",
        "        self.bv = tf.Variable(tf.random.normal((nv, 1)), trainable=True) \n",
        "        self.bh = tf.Variable(tf.random.normal((nh, 1)), trainable=True)\n",
        "        \n",
        "    def bernoulli(self, p):\n",
        "        return tf.nn.relu(tf.sign(p - tf.random.uniform(p.shape)))\n",
        "    \n",
        "    def energy(self, v):\n",
        "        b_term = tf.squeeze(tf.matmul(v, self.bv))\n",
        "        linear_tranform = tf.matmul(v, self.W) + tf.squeeze(self.bh)\n",
        "        h_term = tf.reduce_sum(tf.math.log(tf.exp(linear_tranform) + 1), axis=1) \n",
        "        return tf.reduce_mean(-h_term -b_term)\n",
        "    \n",
        "    def sample_h(self, v):\n",
        "        ph_given_v = tf.sigmoid(tf.matmul(v, self.W) + tf.squeeze(self.bh))\n",
        "        return self.bernoulli(ph_given_v)\n",
        "    \n",
        "    def sample_v(self, h):\n",
        "        pv_given_h = tf.sigmoid(tf.matmul(h, tf.transpose(self.W)) + tf.squeeze(self.bv))\n",
        "        return self.bernoulli(pv_given_h)\n",
        "    \n",
        "    def gibbs_step(self, i, vk):\n",
        "        hk = self.sample_h(vk)\n",
        "        vk = self.sample_v(hk)\n",
        "        return i+1, vk\n",
        "    \n",
        "    def gibbs_sample(self, n_samples, n_steps=3):\n",
        "        init = tf.cast(tf.random.uniform(shape=(n_samples, self.nv), maxval=1) <= 0.5, tf.float32)\n",
        "        _, x_samples = tf.while_loop(cond=lambda i, _: i <= n_steps, body = rbm.gibbs_step, \n",
        "                              loop_vars = [0, init], parallel_iterations=1,)\n",
        "        return x_samples\n",
        "    \n",
        "    def call(self, x):\n",
        "        x_samples = self.gibbs_sample(100*len(x))\n",
        "        self.add_loss(self.energy(x) - self.energy(tf.stop_gradient(x_samples)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiRTH627u_pm"
      },
      "source": [
        "def to_freq(data):\n",
        "    data = np.packbits(data.astype(np.int), axis=1, bitorder='little').flatten()\n",
        "    vals, freq = np.unique(data, return_counts=True)\n",
        "    return freq/freq.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sckGt9Ju_pm",
        "outputId": "a6740231-13be-485c-9645-3ddcba3f5d00"
      },
      "source": [
        "from tqdm import trange\n",
        "data_vals = []\n",
        "weights = np.random.normal(size=4)\n",
        "probs = np.abs(np.random.normal(size=4))\n",
        "probs = probs/probs.sum()\n",
        "for _ in trange(1000):\n",
        "    tmp = np.random.choice(4, p=probs, size=5000)\n",
        "    options = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "    X = options[tmp].astype(np.float32)\n",
        "    data_vals.append(weights @ (to_freq(X)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 1522.73it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5nrbl0ku_pn",
        "outputId": "99f9c020-d9d9-4f36-8597-b6ff13400de0"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In9FrgJUu_pn",
        "outputId": "2a5266a0-93d9-4e32-9dce-a9102ccc80dd"
      },
      "source": [
        "rbm = RBM(nh=20)\n",
        "rbm_vals = []\n",
        "rbm.compile(optimizer=tf.optimizers.SGD(0.1))\n",
        "callbacks=[\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20),\n",
        "    tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='loss'),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5)\n",
        "]\n",
        "rbm.fit(X, batch_size=10, verbose=2, epochs=200, callbacks=callbacks)\n",
        "rbm.load_weights('model.h5')\n",
        "to_freq(rbm.gibbs_sample(100000, n_steps=3).numpy()), to_freq(X)\n",
        "for _ in trange(100):\n",
        "    rbm_vals.append(weights @ (to_freq(rbm.gibbs_sample(100000).numpy())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "500/500 - 1s - loss: 0.0129\n",
            "Epoch 2/200\n",
            "500/500 - 1s - loss: 0.0137\n",
            "Epoch 3/200\n",
            "500/500 - 1s - loss: 0.0232\n",
            "Epoch 4/200\n",
            "500/500 - 1s - loss: 0.0185\n",
            "Epoch 5/200\n",
            "500/500 - 1s - loss: 0.0193\n",
            "Epoch 6/200\n",
            "500/500 - 1s - loss: 0.0185\n",
            "Epoch 7/200\n",
            "500/500 - 1s - loss: 0.0088\n",
            "Epoch 8/200\n",
            "500/500 - 1s - loss: 0.0045\n",
            "Epoch 9/200\n",
            "500/500 - 1s - loss: 0.0046\n",
            "Epoch 10/200\n",
            "500/500 - 1s - loss: 0.0018\n",
            "Epoch 11/200\n",
            "500/500 - 1s - loss: 0.0022\n",
            "Epoch 12/200\n",
            "500/500 - 1s - loss: 0.0035\n",
            "Epoch 13/200\n",
            "500/500 - 1s - loss: 0.0018\n",
            "Epoch 14/200\n",
            "500/500 - 1s - loss: 0.0034\n",
            "Epoch 15/200\n",
            "500/500 - 1s - loss: 0.0014\n",
            "Epoch 16/200\n",
            "500/500 - 1s - loss: 0.0034\n",
            "Epoch 17/200\n",
            "500/500 - 1s - loss: 0.0027\n",
            "Epoch 18/200\n",
            "500/500 - 1s - loss: 5.7491e-04\n",
            "Epoch 19/200\n",
            "500/500 - 1s - loss: 0.0021\n",
            "Epoch 20/200\n",
            "500/500 - 1s - loss: 0.0014\n",
            "Epoch 21/200\n",
            "500/500 - 1s - loss: 0.0019\n",
            "Epoch 22/200\n",
            "500/500 - 1s - loss: 0.0027\n",
            "Epoch 23/200\n",
            "500/500 - 1s - loss: 0.0017\n",
            "Epoch 24/200\n",
            "500/500 - 1s - loss: 0.0014\n",
            "Epoch 25/200\n",
            "500/500 - 1s - loss: 4.3101e-04\n",
            "Epoch 26/200\n",
            "500/500 - 1s - loss: 7.6196e-04\n",
            "Epoch 27/200\n",
            "500/500 - 1s - loss: -6.1760e-04\n",
            "Epoch 28/200\n",
            "500/500 - 1s - loss: 3.0844e-04\n",
            "Epoch 29/200\n",
            "500/500 - 1s - loss: 7.6702e-04\n",
            "Epoch 30/200\n",
            "500/500 - 1s - loss: -1.2450e-04\n",
            "Epoch 31/200\n",
            "500/500 - 1s - loss: 3.3098e-04\n",
            "Epoch 32/200\n",
            "500/500 - 1s - loss: -2.6669e-04\n",
            "Epoch 33/200\n",
            "500/500 - 1s - loss: -4.3352e-04\n",
            "Epoch 34/200\n",
            "500/500 - 1s - loss: 2.7970e-04\n",
            "Epoch 35/200\n",
            "500/500 - 1s - loss: -8.9136e-04\n",
            "Epoch 36/200\n",
            "500/500 - 1s - loss: 3.0175e-04\n",
            "Epoch 37/200\n",
            "500/500 - 1s - loss: -6.3159e-04\n",
            "Epoch 38/200\n",
            "500/500 - 1s - loss: -2.8392e-04\n",
            "Epoch 39/200\n",
            "500/500 - 1s - loss: -2.1548e-04\n",
            "Epoch 40/200\n",
            "500/500 - 1s - loss: -5.9087e-04\n",
            "Epoch 41/200\n",
            "500/500 - 2s - loss: -1.2098e-03\n",
            "Epoch 42/200\n",
            "500/500 - 2s - loss: 3.2624e-04\n",
            "Epoch 43/200\n",
            "500/500 - 2s - loss: 8.1980e-05\n",
            "Epoch 44/200\n",
            "500/500 - 2s - loss: -9.4823e-04\n",
            "Epoch 45/200\n",
            "500/500 - 2s - loss: -8.9752e-04\n",
            "Epoch 46/200\n",
            "500/500 - 2s - loss: -4.0876e-05\n",
            "Epoch 47/200\n",
            "500/500 - 2s - loss: -9.5293e-05\n",
            "Epoch 48/200\n",
            "500/500 - 1s - loss: -4.3792e-04\n",
            "Epoch 49/200\n",
            "500/500 - 1s - loss: -8.5187e-04\n",
            "Epoch 50/200\n",
            "500/500 - 1s - loss: -1.8871e-04\n",
            "Epoch 51/200\n",
            "500/500 - 1s - loss: -2.7232e-04\n",
            "Epoch 52/200\n",
            "500/500 - 1s - loss: 5.1786e-04\n",
            "Epoch 53/200\n",
            "500/500 - 1s - loss: 2.9272e-04\n",
            "Epoch 54/200\n",
            "500/500 - 1s - loss: 2.8448e-05\n",
            "Epoch 55/200\n",
            "500/500 - 1s - loss: 8.2754e-05\n",
            "Epoch 56/200\n",
            "500/500 - 1s - loss: -7.2518e-04\n",
            "Epoch 57/200\n",
            "500/500 - 1s - loss: 3.4234e-04\n",
            "Epoch 58/200\n",
            "500/500 - 1s - loss: -2.4080e-04\n",
            "Epoch 59/200\n",
            "500/500 - 1s - loss: -5.8845e-04\n",
            "Epoch 60/200\n",
            "500/500 - 1s - loss: -4.2219e-04\n",
            "Epoch 61/200\n",
            "500/500 - 1s - loss: 6.5264e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.17it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3efQpkzu_pn",
        "outputId": "2f8f33a9-082f-439e-879e-985bdcd027eb"
      },
      "source": [
        "np.round(to_freq(rbm.gibbs_sample(100000).numpy()),3), np.round(to_freq(X),3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.326, 0.147, 0.162, 0.365]), array([0.325, 0.146, 0.164, 0.366]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "tf1EYF10u_pn",
        "outputId": "b7167875-7dba-49e0-a325-938220123444"
      },
      "source": [
        "sns.kdeplot(data_vals, fill=True)\n",
        "plt.axvline(np.percentile(np.array(rbm_vals), 5), c='black', ls='--', lw=1)\n",
        "plt.axvline(np.percentile(np.array(rbm_vals), 95), c='black', ls='--', lw=1)\n",
        "plt.axvline(np.percentile(np.array(rbm_vals), 50), c='red', lw=3)\n",
        "plt.axvline(weights@to_freq(X), c='green')\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6Kok_QwPv2r"
      },
      "source": [
        "# Complex RBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnMET6SiPw5y",
        "outputId": "f79841e7-480a-42e5-fd93-df8af1898b32"
      },
      "source": [
        "psi_z = np.random.normal(size=2) + np.random.normal(size=2) * 1j\n",
        "psi_z = psi_z/np.linalg.norm(psi_z)\n",
        "psi_z"
      ],
      "execution_count": 356,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.0962174 +0.8060157j , 0.46011337-0.35968959j])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxGt_2MiQMiy"
      },
      "source": [
        "COBS = np.array([\n",
        "    [\n",
        "     [-1/np.sqrt(2), 1/np.sqrt(2)], # complex conjugate of 1st x vector in z basis\n",
        "     [ 1/np.sqrt(2), 1/np.sqrt(2)]\n",
        "    ],\n",
        "    [\n",
        "     [1j/np.sqrt(2), 1/np.sqrt(2)], # complex conjugate of 1st y vector\n",
        "     [-1j/np.sqrt(2), 1/np.sqrt(2)]\n",
        "    ],\n",
        "    [\n",
        "     [1, 0],\n",
        "     [0, 1]\n",
        "    ]\n",
        "])\n",
        "def draw_from_psi(psi_z, N=10000, basis=2):\n",
        "    sigma = np.take(COBS, basis, axis=0)\n",
        "    psi_proj = (sigma @ psi_z[:,np.newaxis]).flatten()\n",
        "    probs = psi_proj * np.conj(psi_proj)\n",
        "    res = np.random.multinomial(n=1, pvals=np.real(probs), size=N)\n",
        "    return np.argwhere(res)[:,1]\n",
        "\n",
        "Z_samples = draw_from_psi(psi_z, N=5000, basis=2)\n",
        "X_samples = draw_from_psi(psi_z, N=5000, basis=0)"
      ],
      "execution_count": 357,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4puvIMAYY7SA"
      },
      "source": [
        "class CRBM(tf.keras.models.Model):\n",
        "    def __init__(self, nv=1, nh=5):\n",
        "        super(CRBM, self).__init__()\n",
        "        self.nv, self.nh = nv, nh\n",
        "        self.bv = tf.Variable(initial_value=CRBM.random_normal((nv,1)), dtype=tf.dtypes.complex64)\n",
        "        self.bh = tf.Variable(initial_value=CRBM.random_normal((nh,1)), dtype=tf.dtypes.complex64)\n",
        "        self.W = tf.Variable(initial_value=CRBM.random_normal((nv, nh)), dtype=tf.dtypes.complex64)\n",
        "        v_vecs = np.array([list(\"{0:b}\".format(x).zfill(nv)) for x in np.arange(2**nv)]).astype(np.int)\n",
        "        self.v_vecs = tf.cast(tf.convert_to_tensor(v_vecs), tf.dtypes.complex64)\n",
        "        self.COBS = tf.cast(tf.convert_to_tensor(COBS), tf.dtypes.complex64)\n",
        "    \n",
        "    @staticmethod\n",
        "    def random_normal(shape):\n",
        "        return np.random.normal(size=shape) + 1j*np.random.normal(size=shape)\n",
        "    \n",
        "    def psi(self, v):\n",
        "        \"\"\"\n",
        "        Accepts only length N binary strings\n",
        "        \"\"\"\n",
        "        if tf.rank(v) == 1:\n",
        "            v = tf.expand_dims(v, axis=-1)\n",
        "        elif tf.rank(v) == 2:\n",
        "            v = tf.transpose(v)\n",
        "        ret = tf.linalg.adjoint(self.bv) @ v + tf.reduce_sum(tf.math.log(tf.math.conj(tf.exp(self.bh + tf.linalg.adjoint(self.W) @ v)) + 1), axis=0)\n",
        "        return tf.transpose(tf.exp(ret))\n",
        "\n",
        "    def prob(self, spins, basis):\n",
        "        basis = tf.cast(basis, tf.int64)\n",
        "        indexing = tf.concat((basis, spins), axis=-1)\n",
        "        sigma = tf.math.conj(tf.cast(tf.gather_nd(self.COBS, indexing), tf.dtypes.complex64)) # sigma = <v_i | measured state vector>\n",
        "        psi_vec = self.psi(self.v_vecs)\n",
        "        psi_proj = sigma @ psi_vec\n",
        "        return tf.cast(psi_proj*tf.math.conj(psi_proj)/tf.linalg.norm(psi_vec)**2, tf.float32)\n",
        "\n",
        "    def call(self, measurement):\n",
        "        spins = measurement[0]\n",
        "        basis = measurement[1]\n",
        "        probs = self.prob(spins, basis=basis)\n",
        "        self.add_loss(-tf.math.reduce_mean(tf.math.log(probs)))"
      ],
      "execution_count": 358,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGBzuVZ2dKa6"
      },
      "source": [
        "bs = 100\n",
        "measurements = np.expand_dims(np.concatenate((X_samples, Z_samples), axis=0), axis=-1)\n",
        "bases = np.expand_dims(np.concatenate((np.zeros(len(X_samples)), 2*np.ones(len(Z_samples))), axis=0), axis=-1)"
      ],
      "execution_count": 359,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLNAhPYG0Dlm",
        "outputId": "aba555f8-ce8e-4226-d753-79bc65ad2264"
      },
      "source": [
        "!rm -rf imgs\n",
        "!mkdir imgs\n",
        "import imageio\n",
        "from datetime import datetime\n",
        "import os\n",
        "from qiskit.visualization import plot_bloch_vector\n",
        "class Visualize(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs):\n",
        "        if epoch <= 20:\n",
        "            tmp = psi_z/psi_z[0]\n",
        "            tmp = tmp/np.linalg.norm(tmp)\n",
        "            theta = np.arccos(tmp[0].real)*2\n",
        "            phi = np.angle(tmp[1])\n",
        "\n",
        "            fig = plot_bloch_vector([1,theta,phi], coord_type='spherical', title=f'Epoch {epoch}')\n",
        "            psi = self.model.psi(self.model.v_vecs)\n",
        "            psi = (psi/np.linalg.norm(psi)).numpy().flatten()\n",
        "            tmp = psi/psi[0]\n",
        "            tmp = tmp/np.linalg.norm(tmp)\n",
        "            theta = np.arccos(tmp[0].real)*2\n",
        "            phi = np.angle(tmp[1])\n",
        "            plot_bloch_vector([1,theta,phi], coord_type='spherical', ax=fig.gca(), title=f'Epoch {epoch}')\n",
        "            fig.savefig(f\"imgs/epoch-{str(epoch).zfill(3)}.png\", bbox_inches='tight')\n",
        "    \n",
        "    def on_train_end(self, logs):\n",
        "        images = []\n",
        "        for filename in sorted(os.listdir(\"imgs/\"), key=lambda x: int(x.split('.')[0][-3:])):\n",
        "            images.append(imageio.imread(f\"imgs/{filename}\"))\n",
        "        for _ in range(10):\n",
        "            images.append(imageio.imread(f\"imgs/{filename}\"))\n",
        "        date = datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\")\n",
        "        imageio.mimsave(f'{date}.gif', images)\n",
        "        self.model.load_weights(\"model.h5\")\n",
        "\n",
        "crbm = CRBM(nv=1, nh=5)\n",
        "crbm.compile(optimizer=tf.optimizers.Adam(0.1))\n",
        "callbacks=[\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=30),\n",
        "    tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='loss', verbose=True, save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5, verbose=True, min_lr=1e-5),\n",
        "    tf.keras.callbacks.CSVLogger(\"training.csv\"),\n",
        "    Visualize()\n",
        "]\n",
        "hist = crbm.fit(x=(measurements, bases), verbose=2, epochs=200, callbacks=callbacks, batch_size=200, shuffle=True)"
      ],
      "execution_count": 412,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.71612, saving model to model.h5\n",
            "50/50 - 0s - loss: 0.7161\n",
            "Epoch 2/200\n",
            "\n",
            "Epoch 00002: loss improved from 0.71612 to 0.61793, saving model to model.h5\n",
            "50/50 - 0s - loss: 0.6179\n",
            "Epoch 3/200\n",
            "\n",
            "Epoch 00003: loss improved from 0.61793 to 0.61299, saving model to model.h5\n",
            "50/50 - 0s - loss: 0.6130\n",
            "Epoch 4/200\n",
            "\n",
            "Epoch 00004: loss improved from 0.61299 to 0.61030, saving model to model.h5\n",
            "50/50 - 0s - loss: 0.6103\n",
            "Epoch 5/200\n",
            "\n",
            "Epoch 00005: loss improved from 0.61030 to 0.60696, saving model to model.h5\n",
            "50/50 - 0s - loss: 0.6070\n",
            "Epoch 6/200\n",
            "\n",
            "Epoch 00006: loss did not improve from 0.60696\n",
            "50/50 - 0s - loss: 0.6074\n",
            "Epoch 7/200\n",
            "\n",
            "Epoch 00007: loss did not improve from 0.60696\n",
            "50/50 - 0s - loss: 0.6082\n",
            "Epoch 8/200\n",
            "\n",
            "Epoch 00008: loss did not improve from 0.60696\n",
            "50/50 - 0s - loss: 0.6102\n",
            "Epoch 9/200\n",
            "\n",
            "Epoch 00009: loss did not improve from 0.60696\n",
            "50/50 - 0s - loss: 0.6196\n",
            "Epoch 10/200\n",
            "\n",
            "Epoch 00010: loss did not improve from 0.60696\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
            "50/50 - 0s - loss: 0.6207\n",
            "Epoch 11/200\n",
            "\n",
            "Epoch 00011: loss did not improve from 0.60696\n",
            "50/50 - 0s - loss: 0.6082\n",
            "Epoch 12/200\n",
            "\n",
            "Epoch 00012: loss improved from 0.60696 to 0.60633, saving model to model.h5\n",
            "50/50 - 0s - loss: 0.6063\n",
            "Epoch 13/200\n",
            "\n",
            "Epoch 00013: loss did not improve from 0.60633\n",
            "50/50 - 0s - loss: 0.6067\n",
            "Epoch 14/200\n",
            "\n",
            "Epoch 00014: loss did not improve from 0.60633\n",
            "50/50 - 0s - loss: 0.6063\n",
            "Epoch 15/200\n",
            "\n",
            "Epoch 00015: loss did not improve from 0.60633\n",
            "50/50 - 0s - loss: 0.6067\n",
            "Epoch 16/200\n",
            "\n",
            "Epoch 00016: loss did not improve from 0.60633\n",
            "50/50 - 0s - loss: 0.6064\n",
            "Epoch 17/200\n",
            "\n",
            "Epoch 00017: loss did not improve from 0.60633\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "50/50 - 0s - loss: 0.6064\n",
            "Epoch 18/200\n",
            "\n",
            "Epoch 00018: loss improved from 0.60633 to 0.60630, saving model to model.h5\n",
            "50/50 - 0s - loss: 0.6063\n",
            "Epoch 19/200\n",
            "\n",
            "Epoch 00019: loss improved from 0.60630 to 0.60623, saving model to model.h5\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 20/200\n",
            "\n",
            "Epoch 00020: loss improved from 0.60623 to 0.60620, saving model to model.h5\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 21/200\n",
            "\n",
            "Epoch 00021: loss did not improve from 0.60620\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 22/200\n",
            "\n",
            "Epoch 00022: loss did not improve from 0.60620\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 23/200\n",
            "\n",
            "Epoch 00023: loss improved from 0.60620 to 0.60620, saving model to model.h5\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 24/200\n",
            "\n",
            "Epoch 00024: loss did not improve from 0.60620\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 25/200\n",
            "\n",
            "Epoch 00025: loss improved from 0.60620 to 0.60618, saving model to model.h5\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 26/200\n",
            "\n",
            "Epoch 00026: loss did not improve from 0.60618\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 27/200\n",
            "\n",
            "Epoch 00027: loss did not improve from 0.60618\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 28/200\n",
            "\n",
            "Epoch 00028: loss did not improve from 0.60618\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 29/200\n",
            "\n",
            "Epoch 00029: loss improved from 0.60618 to 0.60617, saving model to model.h5\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 30/200\n",
            "\n",
            "Epoch 00030: loss improved from 0.60617 to 0.60617, saving model to model.h5\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 31/200\n",
            "\n",
            "Epoch 00031: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 32/200\n",
            "\n",
            "Epoch 00032: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 33/200\n",
            "\n",
            "Epoch 00033: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 34/200\n",
            "\n",
            "Epoch 00034: loss improved from 0.60617 to 0.60617, saving model to model.h5\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 35/200\n",
            "\n",
            "Epoch 00035: loss improved from 0.60617 to 0.60617, saving model to model.h5\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 36/200\n",
            "\n",
            "Epoch 00036: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 37/200\n",
            "\n",
            "Epoch 00037: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 38/200\n",
            "\n",
            "Epoch 00038: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 39/200\n",
            "\n",
            "Epoch 00039: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 40/200\n",
            "\n",
            "Epoch 00040: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 41/200\n",
            "\n",
            "Epoch 00041: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 42/200\n",
            "\n",
            "Epoch 00042: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 43/200\n",
            "\n",
            "Epoch 00043: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 44/200\n",
            "\n",
            "Epoch 00044: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 45/200\n",
            "\n",
            "Epoch 00045: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 46/200\n",
            "\n",
            "Epoch 00046: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 47/200\n",
            "\n",
            "Epoch 00047: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 48/200\n",
            "\n",
            "Epoch 00048: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 49/200\n",
            "\n",
            "Epoch 00049: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 50/200\n",
            "\n",
            "Epoch 00050: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 51/200\n",
            "\n",
            "Epoch 00051: loss improved from 0.60617 to 0.60617, saving model to model.h5\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 52/200\n",
            "\n",
            "Epoch 00052: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 53/200\n",
            "\n",
            "Epoch 00053: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 54/200\n",
            "\n",
            "Epoch 00054: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 55/200\n",
            "\n",
            "Epoch 00055: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 56/200\n",
            "\n",
            "Epoch 00056: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 57/200\n",
            "\n",
            "Epoch 00057: loss improved from 0.60617 to 0.60617, saving model to model.h5\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 58/200\n",
            "\n",
            "Epoch 00058: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 59/200\n",
            "\n",
            "Epoch 00059: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 60/200\n",
            "\n",
            "Epoch 00060: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 61/200\n",
            "\n",
            "Epoch 00061: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 62/200\n",
            "\n",
            "Epoch 00062: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 63/200\n",
            "\n",
            "Epoch 00063: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 64/200\n",
            "\n",
            "Epoch 00064: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 65/200\n",
            "\n",
            "Epoch 00065: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 66/200\n",
            "\n",
            "Epoch 00066: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 67/200\n",
            "\n",
            "Epoch 00067: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 68/200\n",
            "\n",
            "Epoch 00068: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 69/200\n",
            "\n",
            "Epoch 00069: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 70/200\n",
            "\n",
            "Epoch 00070: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 71/200\n",
            "\n",
            "Epoch 00071: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 72/200\n",
            "\n",
            "Epoch 00072: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 73/200\n",
            "\n",
            "Epoch 00073: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 74/200\n",
            "\n",
            "Epoch 00074: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 75/200\n",
            "\n",
            "Epoch 00075: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 76/200\n",
            "\n",
            "Epoch 00076: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 77/200\n",
            "\n",
            "Epoch 00077: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 78/200\n",
            "\n",
            "Epoch 00078: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 79/200\n",
            "\n",
            "Epoch 00079: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 80/200\n",
            "\n",
            "Epoch 00080: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 81/200\n",
            "\n",
            "Epoch 00081: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 82/200\n",
            "\n",
            "Epoch 00082: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 83/200\n",
            "\n",
            "Epoch 00083: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 84/200\n",
            "\n",
            "Epoch 00084: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 85/200\n",
            "\n",
            "Epoch 00085: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 86/200\n",
            "\n",
            "Epoch 00086: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n",
            "Epoch 87/200\n",
            "\n",
            "Epoch 00087: loss did not improve from 0.60617\n",
            "50/50 - 0s - loss: 0.6062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "zQZ8RBZhk2zv",
        "outputId": "c7c59c60-eb37-432d-957b-471b1998bb24"
      },
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "grnd_truth = [np.abs(psi_z[0] - psi_z[1])**2/2, np.abs(psi_z[0] + psi_z[1])**2/2, np.abs(psi_z[0] + 1j* psi_z[1])**2/2, np.abs(psi_z[0] - 1j* psi_z[1])**2/2, np.abs(psi_z[0])**2, np.abs(psi_z[1])**2]\n",
        "psi = crbm.psi(crbm.v_vecs)\n",
        "psi = (psi/np.linalg.norm(psi)).numpy().flatten()\n",
        "rbm_pred = [np.abs(psi[0] - psi[1])**2/2, np.abs(psi[0] + psi[1])**2/2, np.abs(psi[0] + 1j* psi[1])**2/2, np.abs(psi[0] - 1j* psi[1])**2/2, np.abs(psi[0])**2, np.abs(psi[1])**2]\n",
        "labels = [r'$\\psi_{x-}$','$\\psi_{x+}$','$\\psi_{y-}$','$\\psi_{y+}$','$\\psi_{z-}$','$\\psi_{z+}$',]\n",
        "x = np.arange(len(labels))\n",
        "width=0.35\n",
        "plt.bar(x-width/2, grnd_truth, width=width, label='Ground Truth')\n",
        "plt.bar(x+width/2, rbm_pred, width=width, label='RBM Predictions')\n",
        "plt.legend()\n",
        "plt.xticks(ticks=x, labels=labels);\n",
        "plt.tight_layout()"
      ],
      "execution_count": 437,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwrDkLZOVdRo",
        "outputId": "2c8a09a2-2191-4f44-f2dc-9de5a423035a"
      },
      "source": [
        "sv = qiskit.quantum_info.Statevector(psi)\n",
        "sv.expectation_value(qiskit.quantum_info.Pauli.from_label(\"Z\"))"
      ],
      "execution_count": 443,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.31409029204352784+0j)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 443
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAjB6iPSasyr",
        "outputId": "bb451e76-9854-4c12-e0c5-337602d74314"
      },
      "source": [
        "rbm_pred"
      ],
      "execution_count": 441,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7435589486295342,\n",
              " 0.256441035638888,\n",
              " 0.0925495574242188,\n",
              " 0.9074504418976822,\n",
              " 0.6570451789716714,\n",
              " 0.34295488695130416]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 441
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfJJbyT0b6Rb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}